# Import necessary libraries
import os
import shutil
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import Xception
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.models import Model

print("Libraries imported successfully!")

# Define the source and destination paths
kaggle_json_src = r"C:\Chest_Xray_Classification\kaggle.json"
kaggle_dir = os.path.expanduser("~/.kaggle")  # Default Kaggle directory

# Create the .kaggle directory if it doesn't exist
os.makedirs(kaggle_dir, exist_ok=True)

# Move kaggle.json to the correct directory
shutil.copy(kaggle_json_src, os.path.join(kaggle_dir, "kaggle.json"))
print("Kaggle API key setup complete!")

# Define dataset paths
base_dir = r"C:\Chest_Xray_Classification\project1"
train_dir = os.path.join(base_dir, "train")
val_dir = os.path.join(base_dir, "val")
test_dir = os.path.join(base_dir, "test")

print(f"Train Directory: {train_dir}")
print(f"Validation Directory: {val_dir}")
print(f"Test Directory: {test_dir}")

# Define image generators for training, validation, and testing
train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

val_test_datagen = ImageDataGenerator(rescale=1.0/255)

# Load images from directories
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(299, 299),  # Xception requires 299x299 images
    batch_size=32,
    class_mode="binary"
)

val_generator = val_test_datagen.flow_from_directory(
    val_dir,
    target_size=(299, 299),
    batch_size=32,
    class_mode="binary"
)

test_generator = val_test_datagen.flow_from_directory(
    test_dir,
    target_size=(299, 299),
    batch_size=32,
    class_mode="binary",
    shuffle=False  # No need to shuffle test data
)

print("Data generators created successfully!")

# Load the Xception model with pretrained weights
base_model = Xception(weights='imagenet', include_top=False, input_shape=(299, 299, 3))

# Freeze the base model layers to prevent training them initially
for layer in base_model.layers:
    layer.trainable = False

# Add custom layers on top of the base model for binary classification (Normal vs Pneumonia)
x = base_model.output
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)  # Dropout for regularization to prevent overfitting
predictions = Dense(1, activation='sigmoid')(x)  # Sigmoid activation for binary output

# Create the final model by combining the base model and custom layers
model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model with Adam optimizer and binary crossentropy loss function
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

print("Model built and compiled successfully!")

from tensorflow.keras.callbacks import EarlyStopping
# Define Early Stopping callback to prevent overfitting
early_stopping = EarlyStopping(
    monitor='val_loss',  # Monitor validation loss
    patience=3,          # Wait for 3 epochs without improvement
    restore_best_weights=True  # Restore weights from best epoch
)

# Train the model with proper step calculation and callbacks
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=20,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,  # Proper step calculation
    validation_steps=val_generator.samples // val_generator.batch_size,     # Same for validation
    callbacks=[early_stopping],  # Include early stopping
    verbose=1  # Show progress bar
)

print("Model training complete!")

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# Predict probabilities for test data
predictions = model.predict(test_generator)

# Convert probabilities to binary class labels (0 or 1)
predicted_classes = (predictions > 0.5).astype(int).reshape(-1)

# True labels from the generator
true_classes = test_generator.classes

# Class labels (folder names)
class_labels = list(test_generator.class_indices.keys())

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Print classification report
print(classification_report(true_classes, predicted_classes, target_names=class_labels))

# Confusion matrix
cm = confusion_matrix(true_classes, predicted_classes)

# Plot confusion matrix heatmap
plt.figure(figsize=(6,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import cv2

# Get file paths from the test generator
file_paths = test_generator.filepaths

# Show first 5 test images with predictions
num_images = 5
plt.figure(figsize=(15, 10))

for i in range(num_images):
    img_path = file_paths[i]
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    plt.subplot(1, num_images, i+1)
    plt.imshow(img)
    plt.axis('off')
    pred_label = class_labels[predicted_classes[i]]
    true_label = class_labels[true_classes[i]]
    plt.title(f"Pred: {pred_label}\nTrue: {true_label}")

plt.show()

model.save('my_model.keras')
print("Model saved successfully!")